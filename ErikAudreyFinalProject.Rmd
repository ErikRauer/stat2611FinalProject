---
title: "Comparing Income across Gender among New Coders"
author: "Erik Rauer & Audrey Le Meur"
date: "5/14/2021"
output:
  pdf_document: default
  html_document: default
abstract: "This is our Abstract"
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Test [@larson_yitbarek_2017]
Again [@larson_2019]

# Method

## Data & Cleaning

The set of data we used for our analysis came from a survey conducted in 2016 by Quincy Larson, the creator of freecodecamp.org, and Saron Yitbarek, the creator of codenewbie.org, two online websites created to teach beginners how to code [@larson_2019]. The survey’s goal was to get data on a wide range of demographic and socioeconomic questions from new coders. With this data, Larson and Yitbarek hoped to better understand the end goals of those beginning to learn how to code, in the hopes that they can better meet their users' needs and to help “understand...the global movement toward coding” [@larson_2019].

Larson and Yitbarek designed the survey to get as many responses as possible while still asking a lot of questions. To do so, they took a variety of precautions. For one, they made the survey completely anonymous. This ensures that those responding would answer more accurately, since they would not have to worry about answers being tracked back to them. Another precaution taken was to make all questions optional, allowing users to skip any they did not want to answer. While this means that some questions might have less answers, it raises the overall response rate by preventing users from being stuck on one question they don’t want to answer and not submitting any answers because of it. In addition to these precautions, the survey was kept as short as possible, preventing users from getting bored and not finishing. To assist in this attempt, Larson and Yitbarek would only display certain questions, if a previous one was answered in a certain way. For example, if a user indicated that they had attended a coding boot camp, they might then be asked which one they attended. Users who responded that they had not been to any boot camps would not see this second question. Finally, Larson and Yitbarek had professional data scientists take a look at the survey and critique the questions, offering advice on how to better word them to minimize bias.

All these precautions proved successful, resulting in the survey receiving more than 15,000 responses. However, all this data was not perfect and had to be cleaned up quite a bit. To start, the survey data was split into two parts. The first consisted of questions related to the past experience, current employment information, and future goals of the participants. The second part was made of questions regarding the demographic and socioeconomic status of the participants. The data from these two parts had to be combined into one large dataset, associating each user’s responses to the first part with those of the second. In addition to this combination, various other steps were done to clean the data. First, obvious outliers were removed. Since this survey was open to the general public, there existed a variety of responses that were clearly not honest, such as a user who reported an income of $20,000,000. Several questions allowed users to respond with ranges of values, such as “200-210”. These ranges were replaced with their average in order to make analysis of the data simpler. Additionally, some questions, such as “How long have you been coding for?”, permitted responses in terms of months or years. Any response that was measured in years was converted to months, allowing the category to simply be in numbers without messing with the scales of the responses. Finally, text answers were normalized to make similar answers the same. For example, the responses “Back-end Web Developer” and “back end web developer”, while being the same answer, might be counted differently in analysis of the data. To prevent this from occurring, they were normalized into one answer, for example both responses might have been changed to be “Back-End Web Developer” instead.


# Data Analysis

```{r, include=FALSE}
library(broom)
library(dplyr)
library(knitr)
library(ggplot2)

actualData <- read.csv("ActualData.csv")

str(actualData)
```

## Comparing last year's earnings across gender

```{r, echo=FALSE, warning=FALSE}

plotData <- actualData %>%
  filter(!is.na(Gender))

#Income
ggplot(data=plotData, aes(x=Gender, y=Income)) + geom_boxplot() + labs(title="Figure 1: Last Year's Income by Gender", y="Income (US Dollars)") + theme(text=element_text(family="serif"), plot.title=element_text(hjust=0.5))

```
```{r, echo=FALSE, include=FALSE}

incomeFilter <- !is.na(actualData$Gender) & !is.na(actualData$Income)

aggregate(actualData$Income[incomeFilter], list(actualData$Gender[incomeFilter]), mean)

aggregate(actualData$Income[incomeFilter], list(actualData$Gender[incomeFilter]), median)

```
```{r, include=FALSE}
# Income
aovIncome <- aov(Income ~ Gender, data = actualData)

summary(aovIncome)

```
```{r, echo=FALSE}

incomeTukey <- tidy(TukeyHSD(aovIncome, "Gender", ordered=T))

incomeTukey <- incomeTukey %>%
  select(Comparison = contrast,
         Estimate = estimate,
         "Lower Bound" = conf.low,
         "Upper Bound" = conf.high,
         "P-Value" = adj.p.value)

kable(incomeTukey, caption="Tukey Results for Previous Year's Income by Gender")

```


## Comparing expected earnings across gender

```{r, echo=FALSE, warning=FALSE}

#Expected Earnings
ggplot(data=plotData, aes(x=Gender, y=ExpectedEarning)) + geom_boxplot() + labs(title="Figure 2: Expected Earnings by Gender", y="Expected Earnings (US Dollars)") + theme(text=element_text(family="serif"), plot.title=element_text(hjust=0.5))

```
```{r, echo=FALSE, include=FALSE}

expectedEarningFilter <- !is.na(actualData$Gender) & !is.na(actualData$ExpectedEarning)

aggregate(actualData$ExpectedEarning[expectedEarningFilter], list(actualData$Gender[expectedEarningFilter]), mean)

aggregate(actualData$ExpectedEarning[expectedEarningFilter], list(actualData$Gender[expectedEarningFilter]), median)
```
```{r, include=FALSE}

# Expected Income
aovExpected <- aov(ExpectedEarning ~ Gender, data = actualData)

summary(aovExpected)

```
```{r, echo=FALSE}

expectedTukey <- tidy(TukeyHSD(aovExpected, "Gender", ordered=T))

expectedTukey <- expectedTukey %>%
  select(Comparison = contrast,
         Estimate = estimate,
         "Lower Bound" = conf.low,
         "Upper Bound" = conf.high,
         "P-Value" = adj.p.value)

kable(expectedTukey, caption="Tukey Results for Expected Earnings by Gender")

```

## Comparing income and expected earnings on whether or not they attended a female coding event

```{r, echo=FALSE, warning=FALSE}

femaleEvents <- c("Ada", "Hackbright Academy", "Ladies Learning Code", "Grace Hopper", "Grace Hopper Academy", "Women Who Code", "Girl Develop It")

femaleEventData <- actualData %>%
  mutate(femaleEvent=(BootcampName %in% femaleEvents) | !is.na(CodeEventDjangoGirls) | !is.na(CodeEventGirlDev) | !is.na(CodeEventRailsGirls) | !is.na(CodeEventWomenCode)) %>% 
  filter(Gender == "female")

maleEventData <- actualData %>%
  mutate(attendedEvent=(!is.na(AttendedBootcamp) & AttendedBootcamp == 1) | (!is.na(CodeEventNone) & CodeEventNone == 1)) %>%
  filter(Gender=="male")

#Income
ggplot(data=femaleEventData, aes(x=femaleEvent, y=Income)) + geom_boxplot() + labs(title="Figure 3: Previous Year's Income by Whether a Women's Coding Event was Attended", x="Attended a Women-Focused Coding Event", y="Income (US Dollars)") + theme(text=element_text(family="serif"), plot.title=element_text(hjust=0.5))

```

Comparing the distribution of the income of women that attended a women-focused coding event with the distribution of the income of women who did not attend such an event shows some differences between the two. Primarily of note is that the first, second, and third quartiles of the distribution of women who attended an event appear to be roughly $10,000 higher than those who didn’t. Performing a student’s t-test confirms what these observations seem to show: the average women who attended a female focused event had a significantly higher (P-Values of 5.482x10-6) income than those who didn’t. This suggests two possibilities: either women who have a higher income tend to be the ones who go to these women focused coding events, or alternatively, these coding events do help increase the income of their attendees, likely by increasing the attendee’s skillset and thus their quality in the eyes of employers.

Similar to the distributions of previous year’s income, Figure 4 shows a difference in the distribution of expected earnings of women who attended women focused coding events and women who did not. In fact, just like the distributions of income, the first, second and third quartiles of the distribution of expected earnings of women who attended a coding event appear to be $10,000 higher than their counterparts in the distribution of women who did not attend an event. Once again, a student’s t-test indicates that there is a significant difference in the average of these two distributions resulting in a P-Value of 2.399x10-11. This means that, on average, women who attended a women focused coding event expect to earn a significantly higher income than those that didn’t. Once again these results suggest two possibilities. Either the women who attend these coding events have a higher confidence in their abilities and the worth of those abilities, or these events lead to their attendees becoming more self-assured in their coding skills, thus increasing their self-estimation of their worth.

```{r, echo=FALSE, warning=FALSE}

#Expected Earnings
ggplot(data=femaleEventData, aes(x=femaleEvent, y=ExpectedEarning)) + geom_boxplot() + labs(title="Figure 4: Expected Earnings by Whether a Female Coding Event was Attended", x="Attended a Women-Focused Coding Event", y="Expected Earnings (US Dollars)") + theme(text=element_text(family="serif"), plot.title=element_text(hjust=0.5))

```
```{r, include=FALSE}

t.test(Income ~ femaleEvent, femaleEventData)

t.test(ExpectedEarning ~ femaleEvent, femaleEventData)

t.test(femaleEventData$Income[femaleEventData$femaleEvent], maleEventData$Income[maleEventData$attendedEvent])

t.test(femaleEventData$ExpectedEarning[femaleEventData$femaleEvent], maleEventData$ExpectedEarning[maleEventData$attendedEvent])

t.test(femaleEventData$Income[!femaleEventData$femaleEvent], maleEventData$Income[!maleEventData$attendedEvent])

t.test(femaleEventData$ExpectedEarning[!femaleEventData$femaleEvent], maleEventData$ExpectedEarning[!maleEventData$attendedEvent])

t.test(maleEventData$ExpectedEarning[maleEventData$attendedEvent], maleEventData$ExpectedEarning[!maleEventData$attendedEvent])

```


# Conclusion

# References
